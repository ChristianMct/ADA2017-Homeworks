{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 - Introduction\n",
    "\n",
    "The notebook is organized as follow:\n",
    "(note that the github render can have some bugs (bad displays) and it might be better to directly download the notebook)\n",
    "\n",
    "* **Data Extraction**\n",
    "* **Dataframes construction**\n",
    "* **Dataset merging**\n",
    "* **Analysis**\n",
    "    1. **Homework question**\n",
    "    2. **Exploratory analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import re\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "from itertools import product\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from nltk.metrics import edit_distance\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 200\n",
    "M = 800 # If you want to run the code, you might want to use lower M (see later)\n",
    "\n",
    "SITE1 = \"https://www.topuniversities.com\"\n",
    "URL1 = SITE1+\"/sites/default/files/qs-rankings-data/357051.txt\"\n",
    "\n",
    "SITE2 = \"https://www.timeshighereducation.com\"\n",
    "URL2 = SITE2+\"/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1, data2 = (rq.get(URL).json().get(\"data\") for URL in (URL1, URL2))\n",
    "\n",
    "display(sorted(list(data1[0].keys())))\n",
    "display(sorted(list(data2[0].keys())))\n",
    "\n",
    "names1, names2 = ([u.get(key) for u in data[:M]] for data, key in ((data1, 'title'), (data2, 'name')))\n",
    "print(\"Extracted %d and %d names\" % (len(names1), len(names2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by fetching all the requested data from both websites. For the first URL (topuniversities), we have to request the data from each university page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = rq.Session()\n",
    "reqs = [(req_id, s.prepare_request(rq.Request('GET', SITE1+entry[\"url\"]))) for req_id, entry in enumerate(data1[:N])]\n",
    "print(len(reqs), \"requests to be sent.\")\n",
    "\n",
    "resps = [(req_id, s.send(req)) for req_id, req in reqs]\n",
    "\n",
    "done = [(req_id, resp.text) for req_id, resp in resps if resp.status_code == 200]\n",
    "failed = [(req_id, resp) for req_id, resp in resps if resp.status_code != 200]\n",
    "\n",
    "print(\"%d done, %d failed.\" % (len(done), len(failed)))\n",
    "\n",
    "non_digit = re.compile('[^0-9]')\n",
    "\n",
    "class_to_labels = {\"total+faculty\": \"fac_c_total\",\n",
    "                   \"inter+faculty\": \"fac_c_inter\",\n",
    "                  \"total+student\":\"stu_c_total\",\n",
    "                  \"total+inter\":\"stu_c_inter\"}\n",
    "\n",
    "\n",
    "def resp_to_counts(req):\n",
    "    req_id, resp = req\n",
    "    page = bs4.BeautifulSoup(resp, \"html.parser\")\n",
    "    top = page.body.find(\"div\", class_=\"view-academic-data-profile\")\n",
    "    numdivs = top.find_all(\"div\", class_=\"number\")\n",
    "    \n",
    "    def get_label(div):\n",
    "        if div == top:\n",
    "            return None\n",
    "        label = class_to_labels.get(\"+\".join(div.get(\"class\")))\n",
    "        return label or get_label(div.parent)\n",
    "    \n",
    "    fac_counts = {(get_label(div), int(re.sub(non_digit,'', div.string))) for div in numdivs}\n",
    "    return req_id, fac_counts\n",
    "\n",
    "print(\"Parsing responses using up to %d threads...\" % mp.cpu_count(), end=\"\") \n",
    "with mp.Pool(mp.cpu_count()) as p:\n",
    "    for req_id, counts in p.map(resp_to_counts, done):\n",
    "        data1[req_id].update(counts)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes construction\n",
    "\n",
    "We turn the raw JSON data into a actual pandas Dataframe object. Notice that we instead of the \"student to staff\" ratio, we prefer to compute the \"staff to student\" ratio so that we only work in a \"the higher the better\" mindset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basecol = [\"title\", \"rank_display\", \"country\", \"region\"]\n",
    "addedcol = [\"fac_c_inter\", \"fac_c_total\", \"stu_c_inter\", \"stu_c_total\"]\n",
    "\n",
    "uni_s1 = pd.DataFrame(data1[:N], columns= basecol+addedcol)\n",
    "uni_s1.rename(columns={\"title\":\"name\", \"rank_display\": \"rank\"},inplace=True)\n",
    "# Convert the rank to a numerical type\n",
    "uni_s1[\"rank\"] = uni_s1[\"rank\"].str.extract('(\\d+)', expand=False).astype(int)\n",
    "\n",
    "#ratio computations for s1 only because they are already available for s2\n",
    "uni_s1['staff_student_ratio'] = uni_s1.apply(lambda row: row.fac_c_total/row.stu_c_total, axis=1)\n",
    "uni_s1['pc_intl_students'] = uni_s1.apply(lambda row: (row.stu_c_inter/row.stu_c_total), axis=1)\n",
    "uni_s1['pc_intl_staff'] = uni_s1.apply(lambda row: (row.fac_c_inter/row.fac_c_total), axis=1)\n",
    "\n",
    "uni_s1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second dataset already provide the ratios, we just have to invert the ```staff_student_ratio``` into a ```student_staff_ratio```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basecol = [\"name\", \"rank\", \"location\", \"stats_pc_intl_students\", \"stats_student_staff_ratio\"]\n",
    "\n",
    "uni_s2 = pd.DataFrame(data2[:N], columns=basecol)\n",
    "uni_s2.rename(columns={\"location\":\"country\",\"stats_pc_intl_students\":\"pc_intl_students\", \"stats_student_staff_ratio\":\"student_staff_ratio\"},inplace=True)\n",
    "\n",
    "uni_s2[\"rank\"] = uni_s2[\"rank\"].str.extract('(\\d+)', expand=False).astype(int)\n",
    "\n",
    "uni_s2[\"pc_intl_students\"]= uni_s2[\"pc_intl_students\"].str.extract('(\\d+)', expand=False).astype(float) / 100\n",
    "\n",
    "#transforming of the ratios for s2 so that they are comparable with the data for s1\n",
    "uni_s2['staff_student_ratio'] = uni_s2.apply(lambda row: 1/float(row.student_staff_ratio), axis=1)\n",
    "\n",
    "uni_s2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets merging\n",
    "\n",
    "We compute the best matchings for university names by creating the matrix of the costs (using edit_distance as a cost function) of all the possible assignments. We then use this matrix to solve the linear sum assignment problem (The linear sum assignment problem is also known as minimum weight matching in bipartite graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col(name):\n",
    "    return np.array([edit_distance(name, n) for n in names2])\n",
    "\n",
    "p = mp.Pool(mp.cpu_count())\n",
    "print(\"Computing cost matrix using %d workers...\" % mp.cpu_count(), end=\"\")\n",
    "\n",
    "costs = np.array(p.map(col, names1))\n",
    "print(\"done\")\n",
    "\n",
    "print(\"Computing optimal assigment...\", end=\"\")\n",
    "id_n1, id_n2 = linear_sum_assignment(costs)\n",
    "sol_costs = costs[id_n1[:N], id_n2[:N]]\n",
    "print(\"Done: cost of solution = %d\" % sol_costs.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method will find an assignment in any case, which means that university names that do not have any real match (no corresponding name in the second dataset) will be matched with other names. To mitigate that issue, we first observe that computing a matching in a larger set of names (here, of the M top universities of both websites) will produce less false matchings in the top N. We can use the solution cost to quantify the quality of our solution. We have seen that increasing values of M produce better results (For M in [200, 400, 800], solution costs for the top N are [1119, 875, 822], namely [5.6, 4.3, 4.1] editions per name).\n",
    "\n",
    "Then, we remove the last outliers/mistakes by simply checking that the matched universities are in the same country. If it is not the case, we consider there is no match and remove this entry from the merged dataset. We show that this simple check is already enough for this dataset by outputing the matchings that differ.\n",
    "\n",
    "Also, we get rid of the universities that are in only one of the two datasets, resulting in a \"non-contiguous\" ranking of lower cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uni_m = uni_s1.join(uni_s2.loc[id_n2[:N]].reset_index(drop=True), rsuffix=\"_2\")\n",
    "uni_m.dropna(inplace=True) # Removed uni that are s\n",
    "\n",
    "uni_m.replace(\"Russian Federation\", \"Russia\", inplace=True)\n",
    "uni_m = uni_m[uni_m[\"country\"] == uni_m[\"country_2\"]].drop(\"country_2\", axis=1) # Remove unmatching countries \n",
    "\n",
    "\n",
    "print(\"Merged dataset is of size: %s\" % len(uni_m))\n",
    "display(uni_m[[\"name\", \"name_2\"]][uni_m[\"name\"] != uni_m[\"name_2\"]]) # Shows a good quality of matching\n",
    "\n",
    "uni_m.drop(\"name_2\", axis=1, inplace=True)\n",
    "\n",
    "uni_m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "\n",
    "##  Homework questions\n",
    "\n",
    "The first questions can be answered directly from the extracted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title(s):\n",
    "    return display(HTML(\"<H3>%s</H3>\" % s))\n",
    "\n",
    "def top(n, var, df):\n",
    "    bests = df.sort_values(var, ascending=False).head(n)\n",
    "    return bests[[\"name\", var]].reset_index(drop=True).set_index('name', append=True)\n",
    "\n",
    "TOP_N = 5\n",
    "\n",
    "\n",
    "\n",
    "#sorting of data with respect to each ratio\n",
    "title(\"Best universities according to the staff/Student ratio\")\n",
    "title(\"<u>Site 1 (%s) </u>:\" % SITE1)\n",
    "display(top(TOP_N, 'staff_student_ratio', uni_s1))\n",
    "title(\"<u>Site 2 (%s) </u>:\" % SITE2)\n",
    "display(top(TOP_N, 'staff_student_ratio', uni_s2))\n",
    "\n",
    "title(\"Best universities according to the ratio of international students\")\n",
    "title(\"<u>Site 1 (%s) </u>:\" % SITE1)\n",
    "display(top(TOP_N, 'pc_intl_students', uni_s1))\n",
    "title(\"<u>Site 2 (%s) </u>:\" % SITE2)\n",
    "display(top(TOP_N, 'pc_intl_students', uni_s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second set of questions requires to compute some aggregation within groups, which we perform using the ```pivot_table``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_s1_countries = uni_s1.pivot_table(index=\"country\", values=[\"staff_student_ratio\", \"pc_intl_students\"])\n",
    "uni_s1_regions = uni_s1.pivot_table(index=\"region\", values=[\"staff_student_ratio\", \"pc_intl_students\"])\n",
    "uni_s2_countries = uni_s2.pivot_table(index=\"country\", values=[\"staff_student_ratio\", \"pc_intl_students\"])\n",
    "\n",
    "title(\"Best countries according to faculty member to student ratio\")\n",
    "title(\"<u>Site 1 (%s) </u>:\" % SITE1)\n",
    "display(uni_s1_countries[[\"staff_student_ratio\"]].sort_values(\"staff_student_ratio\", ascending=False).head())\n",
    "title(\"<u>Site 2 (%s) </u>:\" % SITE2)\n",
    "display(uni_s2_countries[[\"staff_student_ratio\"]].sort_values(\"staff_student_ratio\", ascending=False).head())\n",
    "\n",
    "title(\"Best countries according to international students ratio\")\n",
    "title(\"<u>Site 1 (%s) </u>:\" % SITE1)\n",
    "display(uni_s1_countries[[\"pc_intl_students\"]].sort_values(\"pc_intl_students\", ascending=False).head())\n",
    "title(\"<u>Site 2 (%s) </u>:\" % SITE2)\n",
    "display(uni_s2_countries[[\"pc_intl_students\"]].sort_values(\"pc_intl_students\", ascending=False).head())\n",
    "\n",
    "title(\"Best regions according to international students ratio (website 1 only)\")\n",
    "display(uni_s1_regions[[\"pc_intl_students\"]].sort_values(\"pc_intl_students\", ascending=False).head())\n",
    "title(\"Best regions according to faculty member to student ratio (website 1 only)\")\n",
    "display(uni_s1_regions[[\"staff_student_ratio\"]].sort_values(\"staff_student_ratio\", ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We illustrate these results using bar charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(title, df, color, figsize=(15, 5), legend=None, **kwargs):\n",
    "    f, ax = plt.subplots(figsize=figsize)\n",
    "    df.plot(kind='bar', ax=ax, color=color, title=title, legend=True, fontsize=12, **kwargs)\n",
    "    ax.set_xlabel(df.index.name, fontsize=12)\n",
    "    ax.set_ylabel(\"ratio\", fontsize=12)\n",
    "    ax.set_xticklabels(df.index)\n",
    "    ax.tick_params(axis='x', which='major', pad=15)\n",
    "    if legend:\n",
    "        ax.legend(legend)\n",
    "    display(f)\n",
    "    plt.close(f)\n",
    "\n",
    "plot(\"University mean ratios by region according to site 1's ranking\",\n",
    "     uni_s1_regions.sort_values(\"pc_intl_students\", ascending=False), color=['b','r'],\n",
    "    legend=['International Students ratio', 'Faculty/Student ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we notice that the best region according to site 1 in terms of proportion of international students is Oceania, followed by Europe then North America. In terms of proportion of Faculty Members to Students the best region is North America followed by Asia and Europe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\"University Faculty/Student mean ratio by country according to site 1's ranking\",\n",
    "     uni_s1_countries[\"staff_student_ratio\"].sort_values(ascending=False), color=['r'], legend=['Faculty/Student ratio'])\n",
    "\n",
    "plot(\"University mean proportion of International Students by country according to site 1's ranking\",\n",
    "     uni_s1_countries[\"pc_intl_students\"].sort_values(ascending=False), color=['b'], legend=['International Students ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the rankings of the first website, the best countries are United Kingdom and Australia in terms of proportion of International students while the best are Russia and Denmark according to the Faculty Members to the number of Students ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\"University mean proportion of International Students by country according to site 2's ranking\",\n",
    "     uni_s2_countries[\"staff_student_ratio\"].sort_values(ascending=False), color=['b'], legend=['International Students ratio'])\n",
    "\n",
    "plot(\"University mean proportion of International Students by country according to site 2's ranking\",\n",
    "     uni_s2_countries[\"pc_intl_students\"].sort_values(ascending=False), color=['r'], legend=['Faculty/Student ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the rankings of the second website, the best countries are Luxembourg and United Kingdom in terms of proportion of International students while the best are Denmark and Italy according to the Faculty Members to the number of Students ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis\n",
    "\n",
    "\n",
    "We have already observed that the two datasets have different statistics about the universities. We highlight this with some descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uni_m['rank_diff'] = uni_m['rank']-uni_m['rank_2']\n",
    "uni_m['intl_pc_diff'] = uni_m['pc_intl_students']-uni_m['pc_intl_students_2']\n",
    "uni_m['staff_student_ratio_diff'] = uni_m['staff_student_ratio']-uni_m['staff_student_ratio_2']\n",
    "\n",
    "\n",
    "uni_m[['name', 'rank_diff', 'intl_pc_diff', 'staff_student_ratio_diff']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the distributions of the differences between the two websites datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def densplot(column):\n",
    "    sns.distplot(column)\n",
    "    plt.show()\n",
    "\n",
    "def scatplot(xelem, yelem, xlabel, ylabel, title, polyfit=None):\n",
    "    plt.scatter(xelem, yelem)\n",
    "    if polyfit:\n",
    "        plt.plot(np.unique(xelem), np.poly1d(np.polyfit(xelem, yelem, polyfit))(np.unique(xelem)), 'C2')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densplot(uni_m['rank_diff'])\n",
    "densplot(uni_m['intl_pc_diff'])\n",
    "densplot(uni_m['staff_student_ratio_diff'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that, while not being completely similar, the two datasets are consistent. This is because the distribution of the differences are mostly centered around zero. Nevertheless, we remark that the staff to student ratio difference is shifted by 0.05. This could imply that the two websites did not use the same assumptions when computing this statistic (for exemple, including or not PhD students in the staff). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we now look for correlations between different statistics. We **only** show the ones for which we found an interesting pattern.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatplot(uni_m['rank'], uni_m['fac_c_inter'], 'rank', 'international_staff', 'website 1: International Staff', 5)\n",
    "scatplot(uni_m['rank'], uni_m['stu_c_inter'], 'rank', 'international_students', 'website 1: International Students', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the number of international staff is important in website 1's computation of the rank. However, we notice that the number of international student does not matter so much. This is maybe a tendency to put research forward and education in second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatplot(uni_m['rank'], uni_m['staff_student_ratio'], 'rank', 'staff_student_ratio', 'website 1', 5)\n",
    "scatplot(uni_m['rank_2'], uni_m['staff_student_ratio_2'], 'rank_2', 'staff_student_ratio_2', 'website 2', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that website 1 is giving more importance to the staff to student ratio in the computation of its rank than website 2. The higher the ratio, the better the rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatplot(uni_m['rank_2'], uni_m['fac_c_total'], 'rank_2', 'fac_c_total', 'website 2', 5)\n",
    "scatplot(uni_m['rank_2'], uni_m['stu_c_total'], 'rank_2', 'stu_c_total', 'website 2', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe in both website (but only show for the 2nd one) that the rank is barely correlated (positively) with the faculty size. The second plot shows that top universities tend to have less student. This shows that the staff to student ratio is indeed a very important metric to compute ranks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank combination\n",
    "\n",
    "In order to select the best university according to both rankings, we simply average the rankings.\n",
    "We just want to know the best university and there is no tie for the first one which is Stanford University.\n",
    "In case of ties we would have broken these by putting first the university with the highest ranking. (Example: University of Cambridge (3) would be before Caltech (2) if we had to break the ties since it is ranked 2 in the second website)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_m['combine_rank'] = (uni_m['rank']+uni_m['rank_2'])/2\n",
    "\n",
    "uni_ms = uni_m.sort_values(['combine_rank'])\n",
    "uni_ms[[\"name\", \"combine_rank\", \"rank\", \"rank_2\"]].reset_index(drop=True).head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now relate the rank difference with both ranking, and show what are the implications on our combined ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_m['diff_rank_abs'] = pd.DataFrame.abs(uni_m['rank']-uni_m['rank_2'])\n",
    "uni_m['diff_rank'] = uni_m['rank']-uni_m['rank_2']\n",
    "\n",
    "scatplot(uni_m['rank'], uni_m['diff_rank'], 'rank', 'rank_diff', 'website 1', 5)\n",
    "scatplot(uni_m['rank_2'], uni_m['diff_rank'], 'rank', 'rank_diff', 'website 2', 5)\n",
    "scatplot(uni_m['combine_rank'], uni_m['diff_rank'], 'rank', 'rank_diff', 'website 1&2 combined', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the difference between the two rankings is smaller for high-ranked universities than for lower ranked universities. This could be because the ranking is done more precisely for the top-30 universities than for the others.\n",
    "\n",
    "Moreover, we see an interesting pattern: for a given university in the intersection of both datasets, the second website has a tendency to rank it lower. Our combined rank mitigates this tendancy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
