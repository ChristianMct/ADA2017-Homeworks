{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Applied ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Loading of dataset, TF-IDF, seperation of training, testing and validation sets\n",
    "We load the 20newsgroup dataset using sklearn. Since we are going to create ourselves the traning, testing and validation datasets from the entire datasets, we load the entire newsgroup and not only the train subset as proposed in the proposed tutorial. Also, we load the dataset without the metadata, namely without the headers, footers and quotes as it is recommended by the tutorial. That way, the data from texts can be studied without being masked by too frequent metadata such as the sender's affiliated university."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))\n",
    "pprint(list(newsgroups.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the TfidfVectorizer function to compute TF-IDF features for every article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectors = vectorizer.fit_transform(newsgroups.data)\n",
    "# this allows us to have an idea of the number of words for which the TF-IDF is computed for the articles\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 101322 TF-IDF features computed for 11314 articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.nnz / float(vectors.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was not asked by the exercise but we notice that vectors are quite sparse because there is an average of 66.8 out of 101322 non zero entries by vector.\n",
    "\n",
    "We now split our dataset into a training (80%), a testing (10%) and a validation (10%) set. We use the train_test_split function and procede in two steps. First we seperate the whole set into the training set and a temporary set from which we then create the testing and validation sets. Each observation is paired with its corresponding label (the article category)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We seperate the training dataset from the rest, as a result we obtain the TF-IDF vectors belonging \n",
    "#to the training vectors as well as their corresponding label, namely the nesgroups targets. \n",
    "#We choose to use random_state=None as it means it will use np.random thus the training set is picked randomly.\n",
    "labels_training, labels_tmp, vectors_training, vectors_tmp = train_test_split(newsgroups.target, vectors, test_size=0.2, random_state=None)\n",
    "\n",
    "#We now seperate the tmp set with corresponding labels randomly in half to obtain the testing and validation sets\n",
    "labels_testing, labels_validation, vectors_testing, vectors_validation = train_test_split(labels_tmp, vectors_tmp, test_size=0.1, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Training of random forest, fine tuning of predictor on validation set, model assessment and discussion\n",
    "\n",
    "We train a random forest on our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a grid search to fine tune the n_estimators and max_depth parameters by finding the best classifier accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(n_estimators_list, max_depth_list):\n",
    "    score=0\n",
    "    final_depth=0\n",
    "    final_estimator=0\n",
    "    for depth in max_depth_list:\n",
    "        for n_estim in n_estimators_list:\n",
    "            classifier=RandomForestClassifier(max_depth=depth, n_estimators=n_estim, random_state=None)\n",
    "            classifier.fit(vectors_training, labels_training)\n",
    "            prediction = classifier.predict(vectors_validation)\n",
    "            scoring = metrics.accuracy_score(labels_validation, prediction)\n",
    "            if scoring > score:\n",
    "                score=scoring\n",
    "                final_depth=depth\n",
    "                final_estimator=n_estim\n",
    "    return (score, final_depth, final_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search([50,100,200,500,1000,1500,2000,2500], [1,10,20,30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our grid search, we should use the Random Forest classifier with max_depth=30 and n_estimators=2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=RandomForestClassifier(max_depth=30, n_estimators=2500, random_state=None)\n",
    "classifier.fit(vectors_training, labels_training)\n",
    "prediction = classifier.predict(vectors_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute a confusion matrix of our classification pipeline and use the proposed function to plot it available as an example on the scikit-learn website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.predict(vectors_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function found on scikit-learn to plot the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "confusion = confusion_matrix(labels_testing, prediction)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_confusion_matrix(confusion, classes=newsgroups.target_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_confusion_matrix(confusion, classes=newsgroups.target_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we inspect the `feature_importances_` attribute of our random forest and discuss the obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_index = np.argsort(classifier.feature_importances_)\n",
    "best10 = sorted_index[-1:-11:-1]\n",
    "features = np.array(vectorizer.get_feature_names())[best10]\n",
    "importances = classifier.feature_importances_[best10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "y_pos = np.arange(len(features))\n",
    "ax.barh(y_pos, importances, align='center', color='blue')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(features, size = 15)\n",
    "ax.invert_yaxis()  \n",
    "ax.set_xlabel('Feature Importances')\n",
    "ax.set_title('Top 10 important features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
