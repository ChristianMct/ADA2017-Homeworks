{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2; 10,000 battles Project\n",
    "\n",
    "## Tasks Description\n",
    "\n",
    "Milestone 2 (20%): the project repo contains a notebook with data collection and descriptive analysis, properly commented, and the notebook ends with a more structured and informed plan for what comes next.\n",
    "\n",
    "The tasks involving a large amount of data were pre-run and we simply describe their purposes and outputs while showing how to call them in comments.\n",
    "\n",
    "## Data Collection\n",
    "\n",
    "Data collection was a significant part of our work, given the nature of our original dataset. The task was to go from a 44 Gb large wikipedia dump to clean and normalized features about each battle. As it was shown during the lecture, data collection is in fact an iterative process: new needs in the analysis part may require new data to be extracted, or different transformation applied. Thus, the data collection was organized into a **pipeline** of 3 operations, in order to achieve **composability** and **reproducibility**. We know explain this pipeline as a part of this notebook, the actual code being organized as **python modules**, much more suited for data processing than notebooks.\n",
    "\n",
    "Each step of the pipeline is a **python script** in the `processing` folder. They have the following usage:\n",
    "\n",
    "```shell\n",
    "python script.py file-name-in file-name-out\n",
    "```\n",
    "\n",
    "For the sake of reproducibilty and organization, we used a naming convention for the output files including what step of the pipline was run, and the version of this dataset. Each version of the dataset is then associated with a git tag marking the state of the codebase that generated the file, to avoid confusion when coming back to the very begining of the pipeline each time we have a doubt (see README in the `datasets/` folder). We know describe each of the 3 pipeline operation.\n",
    "\n",
    "### Page extraction\n",
    "\n",
    "**Script**: `page_extraction.py`<br />\n",
    "**Environmnent**: Cluster<br />\n",
    "**Input**: `hdfs:///datasets/wikipedia/enwiki-latest-pages-articles-multistream.xml` (~44 Gb)<br />\n",
    "**Output**: `battle-pages-v.json` (~123 Mb)<br />\n",
    "**Description**:<br />\n",
    "Pages extraction has two main goals, it selects what pages are (entierly) kept in the next step using a regular expression in the title (may be refined later, if we find a better way to isolate a battle related page), and translate from an XML to a JSON representation for easier python processing. It leverages on [pySpark's DataFrame](https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html) and its custom [XML data-source from Databricks](https://github.com/databricks/spark-xml) to provide an SQL-like, parallelized Spark job.\n",
    "\n",
    "\n",
    "### Fields extraction\n",
    "\n",
    "**Script**: `fields_extraction.py`<br>\n",
    "**Envir.**: Local<br>\n",
    "**Output**: `battle-fields-v.json` (~14 Mb)<br>\n",
    "**Description**:<br>\n",
    "This step's purpose is to extract key-value pairs from the raw page [Wikitext](https://www.mediawiki.org/wiki/Wikitext), where keys are identifiers of information contained in the page and values are either a `dict` of other key-values pairs, a `list` of string, or a string (mainly, strings that are actually wikitext). In other words, we parse the page into a tree-like structure on which it will be easier to parse and extract actual features afterward. We mainly (but not exclusively) relied on the presence of an `infobox` [template](https://en.wikipedia.org/wiki/Help:Template) for most of the battle pages. Again, each line contains the tree of a battle. Therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can load all the battle trees like this\n",
    "battles = [json.loads(line) for line in open('../datasets/battle-fields-1.json')]\n",
    "print(\"Number of pages or battles pages\", len(battles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then perform some preliminary assessments about the current state of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [b.get('infobox').get('error') for b in battles]\n",
    "no_infoboxes = sum([1 for e in errors if e==\"no infobox\"])\n",
    "more_infoboxes = sum([1 for e in errors if e==\"more than one infobox\"])\n",
    "\n",
    "print(\"Number of pages that do not contain an infobox \", no_infoboxes)\n",
    "print(\"Number of pages that contains more than one infobox \", more_infoboxes)\n",
    "print(\"Number of pages that do contain an infobox \", len(battles)-no_infoboxes-more_infoboxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We immediately see that the number of page we can extract information from is greately reduced. It later came out that many of the pages in the dump are alias, redirects and discussion pages. However, the new battle count is still comfortably high to provide interesting analysis.\n",
    "\n",
    "We then assess the actual population of the extractable keys, so that we know on what field we can focus our feature extraction effort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([b[\"infobox\"] for b in battles if not b[\"infobox\"].get(\"error\")])\n",
    "f, ax = plt.subplots(figsize=(15, 20))\n",
    "counts = df.count().sort_values(ascending=False)\n",
    "counts = counts[counts > 20]\n",
    "sns.barplot(x=counts, y=counts.index, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these observations, we selected the following set of features to be extracted from the key-value pairs by the next pipeline step (we may add more of them later):\n",
    "- date\n",
    "- coordinates\n",
    "- combatants (combatant1, ...)\n",
    "- result\n",
    "- strengths (strength1, ...) in terms of number of men\n",
    "- casualties (casualties1, ...) in terms of number of men killed/wounded/captured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features extraction\n",
    "\n",
    "**Script**: `features_extraction.py`<br />\n",
    "**Envir.**: Local<br />\n",
    "**Output**: `battle-features-v.json` (~4.1 Mb)\n",
    "**Description**:<br>\n",
    "The final step extract a \"flat\" set of key-value from the preivious step's tree (e.i., values cannot be another `dict`) that we call features. It does so by first further parsing and transforming values from the previous step into a normalized representation, possibly combining multiple ones togheter. This was indeed the most time-consuming part of the current implementation, as it involves parsing sometime highly variable, unormalized free-text data. We elaborate on this aspect for some features in the following subsections. Each of line in the output file contains such set, so it can be convieniently imported in a `pandas.DataFrame` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "battles = pd.DataFrame([json.loads(line) for line in open(\"../datasets/battle-features-0.json\")])\n",
    "print(battles.count())\n",
    "demo_col = [\"combatant_first_1\", \"combatant_first_2\", \"result_combatant_1\", \"result_combatant_2\", \"start_date\", \"end_date\", \"casualties_1\", \"casualties_2\"]\n",
    "battles[demo_col].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive analysis\n",
    "\n",
    "We provide a succint descriptive analysis for the main features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geolocation\n",
    "\n",
    "We begin by showing the geographical coverage of our dataset. This seems to be consistent with the location of wars across history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import HeatMap\n",
    "import folium as fl\n",
    "m = fl.Map()\n",
    "coord_df = battles[[\"latitude\", \"longitude\"]].dropna()\n",
    "coords = [[lat, long] for lat, long in zip(coord_df[\"latitude\"], coord_df[\"longitude\"])]\n",
    "HeatMap(coords).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates\n",
    "\n",
    "We continue by looking at the time domain coverage. It looks like we have a pretty uniform one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "dates = battles[battles.start_date.notna()].start_date\n",
    "date_bc = battles[battles.start_date.notna()].dates_bc\n",
    "\n",
    "X=[datetime.datetime.strptime(date, \"%Y-%m-%d\") for date, bc in zip(dates, date_bc) if not bc]\n",
    "fig, ax = plt.subplots(figsize=(20,1))\n",
    "ax.scatter(X, [1]*len(X),\n",
    "           marker='|', s=100)\n",
    "\n",
    "ax.yaxis.set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "ax.get_yaxis().set_ticklabels([])\n",
    "day = pd.to_timedelta(\"1\", unit='D')\n",
    "plt.xlim(X[0] - day, X[-1] + day)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
