{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def densplot(columns, xlabel, title, axo):\n",
    "    for i,v in enumerate(columns):\n",
    "        sns.distplot(v, ax=axo, kde_kws={\"label\": i})\n",
    "    axo.set_title(title)\n",
    "    axo.set_xlabel(xlabel, fontsize=12)\n",
    "    \n",
    "def scatplot(xelem, yelem, xlabel, ylabel, title, axo, polyfit=None, xlim=None, ylim=None):\n",
    "    axo.scatter(xelem, yelem)\n",
    "    if polyfit:\n",
    "        axo.plot(np.unique(xelem), np.poly1d(np.polyfit(xelem, yelem, polyfit))(np.unique(xelem)), 'C2')\n",
    "    if xlim:\n",
    "        axo.set_xlim(0,xlim)\n",
    "    if ylim:\n",
    "        axo.set_ylim(0,ylim)\n",
    "    axo.set_title(title)\n",
    "    axo.set_xlabel(xlabel, fontsize=12)\n",
    "    axo.set_ylabel(ylabel, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles = pd.DataFrame([json.loads(line) for line in open(\"../datasets/battle-features-0.json\")])\n",
    "print(battles.columns)\n",
    "features = [\"casualties_1\", \"casualties_2\",'strength_1', 'strength_2']\n",
    "results_features = ['result_combatant_1', 'result_combatant_2'] \n",
    "battles[features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create one column victory which will be '0' if combatant_1 won and '1' if combatant_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battlesWithResult = battles.loc[(battles['result_combatant_1'] != '') | (battles['result_combatant_2'] != '')]\n",
    "battlesWithResult[\"win\"] = 0\n",
    "results_features.append('win')\n",
    "y = ['win']\n",
    "battlesWithResult.loc[(battlesWithResult[\"result_combatant_1\"].str.contains('icto')),'win'] = 1\n",
    "battlesWithResult.head()[results_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battlesWithResult = battlesWithResult.loc[(battlesWithResult['casualties_1'] >= 1) & (battlesWithResult['casualties_2'] >= 1) & (battlesWithResult['strength_1'] >= 1) & (battlesWithResult['strength_2'] >= 1)]\n",
    "len(battlesWithResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(battlesWithResult[features]) #needed if we use categorical\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We seperate the training dataset from the rest, as a result we obtain the TF-IDF vectors belonging \n",
    "#to the training vectors as well as their corresponding label, namely the nesgroups targets. \n",
    "#We choose to use random_state=None as it means it will use np.random thus the training set is picked randomly.\n",
    "#labels_training,\\\n",
    "#labels_tmp,\\\n",
    "#vectors_training,\\\n",
    "#vectors_tmp= train_test_split(battlesWithResult[features], battlesWithResult['win'], test_size=0.2, random_state=None)\n",
    "\n",
    "#We now seperate the tmp set with corresponding labels randomly in half to obtain the testing and validation sets\n",
    "#labels_testing,\\\n",
    "#labels_validation,\\\n",
    "#vectors_testing,\\\n",
    "#vectors_validation = train_test_split(labels_tmp, vectors_tmp, test_size=0.1, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(battlesWithResult[features], battlesWithResult['win'], test_size=0.2, random_state=None)\n",
    "X_train_v, X_test_v, y_train_v, y_test_v = train_test_split(X_test, y_test, test_size=0.1, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search(n_estimators_list, max_depth_list):\n",
    "    score=0\n",
    "    final_depth=0\n",
    "    final_estimator=0\n",
    "    for depth in max_depth_list:\n",
    "        for n_estim in n_estimators_list:\n",
    "            classifier=RandomForestClassifier(max_depth=depth, n_estimators=n_estim, n_jobs=-1, random_state=None)\n",
    "            classifier.fit(X_train, y_train)\n",
    "            prediction = classifier.predict(X_train_v)\n",
    "            scoring = metrics.accuracy_score(y_train_v, prediction)\n",
    "            if scoring > score:\n",
    "                score=scoring\n",
    "                final_depth=depth\n",
    "                final_estimator=n_estim\n",
    "    return (score, final_depth, final_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search([1,2,3,4,5,6,7,8,9,10,100,200,300,400,500,600,700,800,900,1000], [b for b in range(1,200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=RandomForestClassifier(max_depth=100, n_estimators=100, n_jobs=-1, random_state=None)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = classifier.predict(X_test_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_test_v))\n",
    "sum(abs(prediction-y_test_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function found on scikit-learn to plot the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "confusion = confusion_matrix(y_test_v, prediction) \n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_confusion_matrix(confusion, classes=features,\n",
    "                      title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_index = np.argsort(classifier.feature_importances_)\n",
    "best10 = sorted_index[-1:-11:-1]\n",
    "features = np.array(features)[best10]\n",
    "importances = classifier.feature_importances_[best10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "y_pos = np.arange(len(features))\n",
    "ax.barh(y_pos, importances, align='center', color='blue')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(features, size = 15)\n",
    "ax.invert_yaxis()  \n",
    "ax.set_xlabel('Feature Importances')\n",
    "ax.set_title('Top 10 important features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do logistic regression to see if better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "propensity = logistic.fit(X_train, y_train)\n",
    "\n",
    "prediction_logistic = propensity.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_logistic.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "almost random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
